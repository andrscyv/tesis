INSTITUTO TECNOLÓGICO AUTÓNOMO DE MÉXICO


 
JUGADOR ARTIFICIAL DE DOMINÓ BASADO EN 
MÉTODOS DE MONTE CARLO

TESIS
QUE PARA OBTENER EL TÍTULO DE
INGENIERO    EN      COMPUTACIÓN
P R E S E N T A
Andrés Cruz y Vera















ASESOR: Dr. Marco Antonio Morales Aguirre
CIUDAD DE MÉXICO                                                       		2020

TABLA DE CONTENIDO


1	INTRODUCCIÓN	3
1.1	CONTEXTO	3
1.2	IDENTIFICACIÓN DEL PROBLEMA	3
1.3	OBJETIVOS	4
1.4	METODOLOGÍA	4
1.5	ORGANIZACIÓN DEL DOCUMENTO	4
2	ANÁLISIS	5
2.1	REQUERIMIENTOS FUNCIONALES	5
2.2	REQUERIMIENTOS NO FUNCIONALES	5
2.3	RESTRICCIONES	5
2.4	TRABAJOS RELACIONADOS	6
3	EL JUEGO DE DOMINÓ	7
3.1	DINÁMICA DEL JUEGO	7
3.2	FACTOR PROMEDIO DE RAMIFICACIÓN	7
3.3	INFORMACIÓN IMPERFECTA	8
4	DISEÑO	9
4.1	ELECCIÓN DE ALGORITMO	9
4.2	ARQUITECTURA	9
4.2.1	Análisis de tablero y jugadas predefinidas	10
4.2.2	Muestreo de fichas desconocidas	11
4.2.3	Búsqueda en árbol de juego con información perfecta	11
4.3	ESTÁNDARES UTILIZADOS	11
5	IMPLEMENTACIÓN	12
5.1	IMPLEMENTACIÓN DE MCTS	12
5.2	IMPLEMENTACIÓN DE LAS REGLAS DE DOMINO	12
5.3	MÓDULO DE MUESTREO	13
6	VALIDACIÓN Y RESULTADOS	14
6.1	VALIDACIÓN DE MCTS	14
6.2	SENSIBILIDAD DE MCTS A SU PARÁMETRO DE BÚSQUEDA	15
6.3	DESEMPEÑO DEL SISTEMA	16
7	CONCLUSIONES	17
8	REFERENCIAS	18










1	Introducción

En el primer capítulo se presentará el problema que aborda el presente trabajo. Se dará el 
contexto histórico de la relación entre los videojuegos y los jugadores artificiales para luego 
identificar el problema y definir tanto los objetivos como la metodología a seguir.

1.1	Contexto

La historia de los juegos por computadora inicia desde la década de 1950 en el ámbito 
académico y en los años setenta y ochenta gana popularidad para el público en general. Los 
videojuegos han tenido un gran impacto en la cultura popular, así como en grandes figuras 
de la computación que tuvieron su primer acercamiento a los ordenadores por medio de 
estos y del lenguaje BASIC

Asimismo, los juegos de mesa han tenido un papel importante en el desarrollo del área de 
inteligencia artificial siendo una área muy fructífera de investigación como en el caso del 
ajedrez y la famosa contienda entre Deep Blue y Garry Kasparov

1.2	Identificación del problema

 El desarrollo de videojuegos es un ámbito multidisciplinario en donde se utilizan técnicas 
de inteligencia artificial para complementar la experiencia de juego del usuario. Los 
jugadores artificiales (o bots) cumplen un papel importante como contrincantes o 
personajes secundarios dentro del juego. 

Con miras a desarrollar una versión online del juego de dominó con un modelo de 
monetización basado en anuncios, se tiene como uno de los objetivo maximizar el número 
de impresiones de los anuncios en el usuario. Así, es necesario proveer una experiencia 
atractiva que tenga como efecto que el usuario pase un largo tiempo activo en la página.

El lanzamiento a mercado de un juego multijugador online presenta distintos retos. Entre 
ellos, existe la necesidad de crear una base mínima de usuarios que permita tener un tiempo 
razonable de espera para poder encontrar una partida a la cual unirse. Una forma de 
solventar parcialmente este obstáculo, particularmente en las primeras fases del 
lanzamiento, es contar con jugadores artificiales que suplementen la falta de contrincantes 
humanos.

Así, es deseable contar con un jugador artificial que permita a los usuarios iniciar una 
partida aun en las circunstancias en que no cuenten con suficientes personas para completar 
los equipos. Al momento en que se realiza este escrito, no se ha encontrado una 
implementación de código abierto de un jugador artificial para el juego de dominó (con las 
reglas que se usan en latinoamérica) que cuente tanto con una licencia que permita su uso 
comercial así como una interfaz de programación diseñada para su integración a un juego 
de tiempo real con usuarios humanos.



1.3	Objetivos

Implementar un programa de computadora que sea capaz de jugar en una partida de dominó 
como parte de un equipo de dos participantes que compiten con dos contrincantes.

1.4	Metodología

Para la implementación del bot, se decidió utilizar la metodología de cascada debido a que 
el alcance y la funcionalidad del proyecto es relativamente pequeña.

1.5	Organización del documento

1.	Introducción
2.	Análisis de requisitos del software
3.	El juego de dominó
4.	Diseño del programa
5.	Implementación 
6.	Validación
7.	Conclusiones























2	Análisis

Una vez que se ha identificado el problema, se formulará una primera aproximación a la 
solución por medio de los requerimientos funcionales que debe cumplir, así como por las 
restricciones que debe satisfacer. También se mostrarán trabajos relacionados.

2.1	Requerimientos funcionales

El programa generará una jugada a partir del estado actual del juego. Es decir, el progama 
recibirá como entrada una representación de sus fichas asignadas así como de las fichas 
tiradas por los otros participantes y como salida indicará cual de sus fichas debe jugarse. 

Tambíen será posible elegir distintos niveles de juego para el programa

2.2	Requerimientos no funcionales

El programa debe generar las jugadas en un tiempo razonable. Debe siempre terminar la 
ejecución antes de un lapso predeterminado para poder utilizarse en un juego de tiempo real 
contra contrincantes humanos y no debe poseer información sobre las manos de sus 
contrincantes ni de su pareja de equipo.

En segundo lugar, el desempeño del programa tiene que ser mejor que la estrategia más 
sencillas posible (el jugador greedy): de entre las fichas que se pueden bajar siempre se 
elije la de mayor puntaje. Una jugada greedy es sumamente barata de calcular. De no 
cumplirse con este requisito no tendría sentido utilizar una estrategía más compleja y 
costosa en tiempo y recursos computacionales. 

Así, se pone como meta que un equipo de los jugadores artificiales debe vencer a un equipo 
de jugadores greedy en al menos 70% de las partidas. Se considera que este margen es el 
minimo para justificar el uso de un algoritmo distinto a la estrategía greedy.

Por último, debe exponer una API sencilla para ser integrado a distintas interfaces, tanto 
aplicaciones web como móviles.

2.3	Restricciones

El software a desarrollar cuenta con dos restricciones principales. En primer lugar, en 
cuanto a los recursos para implementar la solucion, se cuenta con un periodo aproximado 
de 6 meses para completar el desarrollo del sistema así como de un solo desarrollador (el 
autor de este trabajo). 

En segundo lugar, el sistema debe cumplir con los requerimientos funcionales y no 
funcionales dentro de un ambiente de ejecución en la nube con un costo razonable. Es 
dificil estimar el costo de los recursos computacionales que consumirá la solución, pues 
depende de la cantidad de usuarios del sistema así como de su comportamiento de uso. No 
se cuenta con los datos necesarios para estimar la naturaleza de la carga a la que el sistema 
debe hacer frente pero se puede definir unas caracteristicas mínimas del ambiente de 
ejecución en el cual la solución debe correr.

Como un punto de referencia, se ha elegido la instancia más modesta de la categoría de 
servidores de proposito general de Digital Ocean. Dicho servidor cuenta con ocho 
gigabytes de memoria RAM y con dos procesadores virtuales. La máquina virtual corre 
sobre procesadores Intel Xeon Skylake con una velocidad base de 2.7 ghz y con máxima 
velocidad de 3.7 ghz. El costo del servidor es de sesenta dólares al mes. Se eligió Digital 
Ocean por los creditos que regala para probar los servidores.

Si el sistema no puede correr en un servidor de esta naturaleza, es muy probable que en una 
escala más grande el costo de la solución sea prohibitivo para su uso.

2.4	Trabajos relacionados

Uno trabajo importante en el ambito de algoritmos  para juegos de información imperfecta 
lo realiza Ginsberg  (2001).  Con esta metodología logra implementar un jugador de Bridge 
de nivel experto. 

Por otra parte, un jugador artificial en un contexto de incertidumbre puede estudiarse desde 
la perspectiva de procesos de decisión de markov como en la disciplina de aprendizaje por 
refuerzo. En este campo es importante el trabajo de Mnih et al. (2013) que es uno de los 
primeros en integrar aprendizaje profundo a los algoritmos de aprendizaje por refuerzo para 
la creación de agentes en el juego de atari.

Long et al. (2010) realizaron un trabajo en donde , a partir de árboles de juego sintéticos, 
definen indicadores estadísticos que les permiten identificar propiedades importantes de 
juegos de información imperfecta en los que el método de Perfect Information Monte Carlo 
(PIMC)  se puede adaptar exitosamente. Dicho trabajo extiende la línea de investigación 
sobre las limitaciones de PIMC en el contexto de información imperfecta que inician Frank 
y Basin (1998)

Asimismo, se recuperó de la web un proyecto de licenciatura sobre un jugador artificial 
para dominó (en el texto se le refiere como Latin-American dominoes) desarrollado por 
Angeris y Li (2016) de la universidad de Stanford. El proyecto consiste en simulaciones 
para contrastar distintas algoritmos pero no tiene la finalidad de ser consumido como una 
API.









3	El juego de dominó

El dominó es un juego conocido alrededor de todo mundo por lo que existen distintas 
modalidades de juego. En esta sección se define el tipo de dominó del que trata este trabajo. 
Posteriormente, se discuten algunas propiedades importantes del juego que permiten hacer 
una estimación de su complejidad y compararlo con la complejidad de otros juegos de 
mesa.

3.1	Dinámica del juego

El juego se compone por veintiocho fichas, cada una marcada con dos números entre el 
cero y el seis. Al iniciar la partida, se revuelven aleatoriamente las fichas y se reparten siete 
a cada uno de los cuatro jugadores. Los jugadores se dividen en dos equipos y se 
encuentran sentados en circulo, de tal forma que no hay dos jugadores del mismo equipo 
adyacentes.

El jugador con la ficha de dos seises es el primero en tirar y el orden de las tiradas sigue a 
la derecha. En cada turno, el jugador puede bajar una ficha si tiene algun número en común 
con los extremos externos de las fichas que ya se han jugado. El objetivo del juego es ser el 
equipo con el primer jugador que ha bajado todas sus fichas o , en caso de que ningun 
jugador pueda bajar fichas, ser el equipo cuyas fichas sumen el mínimo número de puntos. 

3.2	Factor promedio de ramificación

Un componente de la complejidad del juego es el número promedio de acciones que cada 
jugador puede tomar en su turno, tambien conocido como factor promedio de ramificación. 
Un cálculo analítico de este factor es dificil, pues depende de la repartición aleatoria al 
inicio del juego así como de la estrategia de cada jugador. Para obtener una estimación del 
factor se realizó la simulación de diez mil juegos con dos equipos de jugadores greedy y se 
obtuvo los resultados mostrados en la siguiente gráfica


En la figura se muestra, en el eje vertical, el número promedio de fichas que un jugador 
puede tirar en el turno indicado en el eje horizontal. El primer jugador siempre puede tirar 
cualquiera de sus fichas. Después de él, los jugadores pueden tirar 3 o menos fichas en 
promedio. Este factor de ramificación es pequeño si se compara al de otros juegos de mesa 
como el ajedrez, el cual tiene un factor estimado entre 31 y 35 movimientos.

3.3	Información imperfecta

El segundo componente que influye en la complejidad del juego es la incertidumbre 
asociada a las fichas que no se conocen. Para obtener una medida de esta incertidumbre se 
calculó el número de configuraciones posibles de la información escondida. Desde la 
perspectiva del primer jugador en tirar y suponiendo que todos los jugadores bajan una 
ficha, se puede calcular el número de formas distintas en que se pueden repartir las fichas 
que no se conocen para cada vuelta del juego (cada vez que vuelve a ser turno del primer 
jugador ) y se obtuvo la siguiente tabla.

Vuelta 
Posibles formas de repartir las fichas desconocidas
1
400 millones
2
17 millones
3
750 mil
4
34 mil
5
1600
6
90
7
6

Tomando en cuanta ambos componentes de la complejidad, se concluye que la 
incertidumbre asociada a la información imperfecta en las primeras vueltas del juego 
muestra ser el mayor reto a superar. 














4	Diseño

Ya que se ha identificado el problema, su contexto y se ha delimitado los requerimientos 
funcionales y restricciones que debe satisfacer la solución se pasará a definir el diseño de 
ésta así como las posibles alternativas.


4.1	Elección de algoritmo

El principal reto en la implementación del jugador artificial es que el juego de dominó es de 
información imperfecta. Existen dos alternativas principales de algoritmos que pueden 
utilizarse en este tipo de juegos.

En primer lugar, existen algoritmos de aprendizaje por refuerzo que han sido utilizados 
exitosamente en juegos con incertidumbre e información escondida. El algoritmo de 
Counterfactual Regret Minimization ha sido utilizado para crear jugadores de póker. Dicho 
algoritmo utiliza un enfoque iterativo en el que se busca aproximar una función que para 
cada estado del juego defina una acción óptima.

Por otro lado, existe el algoritmo Perfect Information Monte Carlo (PIMC). En este 
algoritmo se busca transformar el juego de información imperfecta en un conjunto de 
juegos de información perfecta congruentes con el estado actual del juego. El conjunto es 
una muestra aleatoria de los posibles escenarios en los que el jugador se puede encontrar. 
En cada uno de estos escenarios se realiza búsqueda en árbol y al final se toma la acción 
que en el mayor número de escenarios llevó a una victoria.

Se considera que PIMC muestra una ventaja sobre la primera alternativa por su simpleza y 
facilidad de implementación. Así mismo, permite aprovechar la experiencia previa que el 
desarrollador ha tenido implementando jugadores basados en búsqueda en árbol. Dadas las 
restricciones del desarrollo, se llegó a la conclusión que PIMC sería la mejor alternativa 
para los fines de este trabajo.

4.2	Arquitectura

El programa consta de los siguientes módulos:

1.	Análisis del tablero y jugadas predefinidas
2.	Muestreo de fichas desconocidas (Determinization)
3.	Búsqueda en árbol de juego con información perfecta


El sistema recibe la representación del estado actual del juego externamente. Cada módulo 
procesa su entrada y tiene como salida la entrada del siguiente módulo. La salida del último 
módulo es la respuesta final del sistema completo.

4.2.1	Análisis de tablero y jugadas predefinidas

En la primera etapa del sistema, se realiza un análisis del estado del juego que se recibe 
como parámetro. En este análisis se busca extraer información necesaria para el muestreo 
de la siguiente etapa, así como determinar si existe una jugada predefinida para el estado 
actual del juego.

 Las circunstancias para utilizar una jugada predeterminada son dos. La primera es si sólo 
se tiene una jugada posible, en cuyo caso se realiza dicha jugada sin iniciar el proceso 
costoso de búsqueda. La segunda es en el primer turno del juego, en donde puede ser 
deseable incorporar conocimiento experto del dominio para elegir una acción cuando no se 
cuenta con suficiente información para que el sistema calcule una jugada efectiva en el 
límite de tiempo establecido.

Si existe una jugada predefinida se omitirá la ejecución de los demás módulos y la jugada 
será la salida del sistema. En otro caso, a partir de la historia del juego se calcularán las 
fichas que aun no han sido tiradas y el número de fichas que tiene cada jugador. Este 
resultado se pasará al siguiente módulo.



4.2.2	Muestreo de fichas desconocidas

Siguiendo el algoritmo de PIMC, es necesario generar un conjunto de posibles escenarios 
en los que se puede encontrar el jugador. En este caso, los escenarios se diferencian por las 
fichas que poseen los otros jugadores. Ya que se cuenta con el conjunto de fichas que aun 
no se han jugado, se puede simular el proceso de repartir las fichas aleatoriamente a los 
otros jugadores y así generar los escenarios. Un escenario se conforma de un arreglo en 
donde se guardan las fichas que se le repartieron aleatoriamente a cada jugador.  

El número de simulaciones que se realizan es un parámetro del sistema que impacta su 
comportamiento en dos formas. Entre más simulaciones se realizan, aumenta el tiempo de 
ejecución. Entre menos simulaciones, el sistema toma en cuenta menos escenarios y el 
desempeño del jugador empeora. 

Al final, se recopilan los distintos escenarios en un arreglo y se pasan al siguiente módulo.

4.2.3	Búsqueda en árbol de juego con información perfecta

Una vez que se ha transformado el juego en un conjunto de escenarios en los que se 
conocen las fichas de los oponentes, es posible calcular una acción óptima para cada uno de 
los escenarios. La ficha que el jugador artificial tirará será aquella que en el mayor número 
de escenarios fue óptima.

Para hacer el cálculo de la jugada óptima hay distintas alternativas. Negamax, Alpha-Beta 
Prunning y Monte Carlo Tree Search (MCTS) son los principales candidatos para realizar 
búsqueda en árbol de juego con información perfecta

Se eligió el algoritmo MCTS debido a dos características que no comparte con las dos 
primeras opciones. En primer lugar, es posible correr el algoritmo sin necesidad de una 
heurística, es decir, de una función que estime la utilidad de un estado del juego. En 
segundo lugar, MCTS es un algoritmo anytime, lo que significa que la ejecución puede 
detenerse en un intervalo arbitrario de tiempo y el algoritmo regresará la mejor jugada que 
ha encontrado hasta ese momento.

La segunda propiedad es particularmente apropiada para este sistema ya que permite 
controlar el tiempo de ejecución total modificando el tiempo que se invierte en calcular la 
acción óptima en cada uno de los escenarios.


4.3	Estándares utilizados

Como parte de la API que el sistema expondrá para ser integrado con otras plataformas se 
decidió que la comunicación de información se haga con el estándar JSON (ECMA-404) 
debido a su flexibilidad y facilidad de uso. Asimismo, se utilizará el estándar PEP8 que 
define una guía de estilo y mejores prácticas para escribir código en Python.
5	Implementación 

En este capítulo se describe la implementación del sistema basada en el diseño previamente 
establecido. Primero se discute la librería utilizada como implementación del algoritmo 
MCTS : mctspy. Posteriormente, se muestra la clase que implementa las reglas del juego de 
dominó y su integración a mctspy. Por último, se comenta la integración del módulo de 
muestreo con el algoritmo MCTS

5.1	Implementación de MCTS

Una parte central del sistema es el algoritmo MCTS. Después de buscar librerías 
alternativas en el Índice de Paquetes de Python (PyPI por sus siglas en inglés) se decidió 
utilizar la librería mctspy de Kamil Czarnogórski. El paquete se encuentra publicado como 
código abierto en Github bajo la licencia MIT. 

El repositorio cuenta con escaza documentación, pero el estilo de programación es claro y 
sencillo, lo que facilita la lectura del código fuente. Para poder utilizar mctspy para un 
juego en particular es necesario implementar una clase que represente el estado del juego, 
así como los métodos que requiere el algoritmo. El repositorio cuenta con un ejemplo de 
implementación para el juego de gato a partir del cual se puede identificar la interfaz que 
debe satisfacer el estado del juego.

Una vez que se ha implementado la interfaz se puede construir un objeto 
MonteCarloTreeSearch con el cual se puede invocar la ejecución de MCTS. La clase 
requiere un parámetro que determina el número de iteraciones de MCTS que se ejecutan.

5.2	Implementación de las reglas de domino

Las reglas del juego se implementaron dentro de la clase que representa el estado del juego. 
La interfaz que dicha clase debe satisfacer consiste en los siguientes métodos:

•	game_result
•	is_game_over
•	is_move_legal
•	move
•	get_legal_actions

Las manos de los jugadores se modelaron como una lista de conjuntos. Cada ficha es 
representada como un conjunto de dos números que corresponden a los puntos de la pieza. 
Así, la clase cuenta con los métodos necesarios para transformar el estado del juego de 
forma consistente con las reglas del dominó.




5.3	Módulo de muestreo


Por último, se implementó un algoritmo de muestreo de las posibles formas de repartir las 
fichas que no se conocen como se muestra en el siguiente pseudocódigo. 



En el algoritmo de la figura anterior se representa la mano de cada jugador como un 
conjunto de fichas para poder explotar las operaciones de conjuntos del lenguaje Python. 
Primero se calcula una muestra para la mano del primer jugador a la derecha. Luego se 
calculan las manos de los jugadores posteriores con las fichas que aun no se han repartido.

















6	Validación y Resultados

En esta sección se muestran los resultados obtenidos después de la implementación. En 
primer lugar se realizaron un conjunto de pruebas para validar que el sistema tuviera las 
propiedades deseadas. Se validó que el último módulo, la búsqueda en árbol de información 
perfecta, calculara jugadas con buen desempeño. Asímismo, se corrieron simulaciones para 
tener una idea sobre la sensibilidad de los parámetros de MCTS. Por último se muestra el 
desempeño del sistema y se contrasta con los requerimientos y restricciones planteadas al 
inicio del escrito.

6.1	Validación de MCTS

A lo largo del desarrollo, la metodología de  Test Driven Development fue útil para ganar 
certidumbre sobre el correcto funcionamiento del programa. Aun así, contar con pruebas 
unitarias no asegura que las partes del sistema funcionen correctamente en conjunto. 
Después de integrar las reglas de dominó con MCTS, era necesario validar que el resultado 
de la búsqueda fuera una acción con buen desempeño. 

Para verificar el funcionamiento del último módulo se simularon mil juegos de dominó con 
las fichas abiertas entre un equipo MCTS y un equipo greedy . 

En la figura anterior tenemos una gráfica del resultado de las simulaciones. En el eje 
horizontal se muestra el número de iteraciones que se le permitió ejecutar a MCTS para 
cada tiro. Se corrieron seis simulaciones con distintas configuraciones de MCTS de mil 
juegos cada una. Podemos observar que muy rápidamente se llega a superar al equipo 
greedy. Con menos de 20 iteraciones, la búsqueda en árbol logró vencer al jugador greedy 
en 80% de los juegos. La gráfica sugiere que el desempeño del equipo MCTS converge 
cuando se le permiten 90 iteraciones a la búsqueda.

El desempeño observado nos indica que MCTS está calculando buenas jugadas y que el 
módulo funciona correctamente.

6.2	Sensibilidad de MCTS a su parámetro de búsqueda

El resultado anterior sugería que con noventa iteraciones la decisión de MCTS converge. Si 
sucediera así, la decisión que toma MCTS sería la misma sin importar si se corre con 
noventa iteraciones o más y dos equipos contrincantes MCTS con parámetros distintos 
deberían tener el mismo desempeño y ganar en 50% de los juegos cada uno. Se puso a 
prueba esta hipótesis simulando juegos entre un equipo con número de iteraciones fija 
(250) contra un equipo de parámetro variable. Se corrieron las simulaciones para ocho 
valores distintos del parámetro de búsqueda.



De la figura anterior, se puede notar que la hipótesis era incorrecta. A pesar de que el 
desempeño de MCTS contra greedy no es sensible al parámetro con valores mayores a 
noventa, el desempeño general sigue dependiendo del parámetro. Un equipo MCTS con 
doscientas cincuenta iteraciones tiene mejor desempeño que un equipo con menos 
iteraciones.

De lo anterior se deduce que cuando se compite contra un equipo greedy no es necesario 
correr muchas iteraciones en MCTS para calcular buenas jugadas pero es posible que el 
desempeño sea menor contra jugadores más fuertes. La figura 4 también sugiere que MCTS 
converge a partir de las doscientas cincuenta iteraciones, pues los puntos posteriores oscilan 
alrededor del 50%, comportamiento que se esperaría de equipos con desempeño igual. 
Inclusive al duplicar las iteraciones a quinientos no parece haber cambio significativo en el 
porcentaje de victorias.

6.3	Desempeño del sistema

El análisis anterior fue útil para encontrar una combinación de parámetros adecuada para 
satisfacer los requerimientos y las restricciones del problema. El sistema necesita que se 
definan dos parámetros. El número de iteraciones de búsqueda y el número de escenarios 
que se simulan. Ya que el desempeño de MCTS contra greedy no requería un gran número 
de iteraciones, se decidió correr veinte iteraciones de MCTS por cada escenario. Por otro 
lado, se eligió simular cien escenarios por tiro.

Se simularon mil juegos de dominó (donde cada jugador sólo conoce sus fichas) entre el 
equipo PIMC contra un equipo greedy. El sistema consiguió 74% de victorias y el tiempo 
que tomó en cada tirada fue de 1.2 segundos corriendo en el servidor de Digital Ocean.




















7	Conclusiones

Se logró implementar un sistema que satisface los requerimientos funcionales y no 
funcionales dentro de las restricciones establecidas. Se ha demostrado que el método 
presentado es una solución factible para un sistema de jugadores artificiales en una 
plataforma de dominó online. Lineas de desarrollo que podrían explorarse a fúturo sería 
análizar el comportamiento del sistema con datos de usuarios humanos, así como el 
comportamiento de  PIMC cuando los equipos se conforman de jugador humano y jugador 
artificial.



































8	Referencias

Angeris, G., & Li, L. (2016). CS 221 Project Final : DominAI. Recuperado de 
https://web.stanford.edu/~guillean/papers/dominai.pdf	
Frank, I., and Basin, D. 1998. Search in games with in- complete information: A case study 
using bridge card play. Artificial Intelligence 87–123. 
Ginsberg, M. L. (2001). GIB: Imperfect Information in a Computationally Challenging 
Game. Journal of Artificial Intelligence Research, 14, 303-358. 
https://doi.org/10.1613/jair.820

Long, Jeffrey Richard et al. “Understanding the Success of Perfect Information Monte 
Carlo Sampling in Game Tree Search.” AAAI (2010).

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D. & Riedmiller, 
M. (2013). Playing Atari with Deep Reinforcement Learning. , .


1

1

